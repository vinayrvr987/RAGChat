{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMml9JlBKzjFYXb28mdnVS6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinayrvr987/RAGChat/blob/master/experiments/Agentic_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain_community wikipedia arxiv langchain_huggingface langchain_text_splitters chromadb langchain_groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NEYjRk77z3oT",
        "outputId": "0f5c5166-3b29-4d34-b6e3-e938acef185e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.11/dist-packages (1.4.0)\n",
            "Requirement already satisfied: arxiv in /usr/local/lib/python3.11/dist-packages (2.2.0)\n",
            "Requirement already satisfied: langchain_huggingface in /usr/local/lib/python3.11/dist-packages (0.3.1)\n",
            "Requirement already satisfied: langchain_text_splitters in /usr/local/lib/python3.11/dist-packages (0.3.9)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (1.0.16)\n",
            "Requirement already satisfied: langchain_groq in /usr/local/lib/python3.11/dist-packages (0.3.7)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.74)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.13)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (4.13.4)\n",
            "Requirement already satisfied: feedparser~=6.0.10 in /usr/local/lib/python3.11/dist-packages (from arxiv) (6.0.11)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain_huggingface) (0.21.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.33.4 in /usr/local/lib/python3.11/dist-packages (from langchain_huggingface) (0.34.4)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.3.0)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.14.1)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.22.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.36.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.74.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.16.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (33.1.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.11.1)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.25.0)\n",
            "Requirement already satisfied: groq<1,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from langchain_groq) (0.31.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (25.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.11/dist-packages (from feedparser~=6.0.10->arxiv) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.30.0->langchain_groq) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.30.0->langchain_groq) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.30.0->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.4->langchain_huggingface) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.4->langchain_huggingface) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.4->langchain_huggingface) (1.1.7)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.36.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.36.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.57b0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (2.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
        "# Make sure your LangSmith API key is correctly set in Colab secrets.\n",
        "LANGCHAIN_API_KEY = userdata.get('LANGCHAIN_API_KEY')\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"Agentic AI exp\"            # Optional but useful\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "\n",
        "# Add print statements to confirm environment variables are set\n",
        "print(f\"LANGCHAIN_TRACING_V2: {os.environ.get('LANGCHAIN_TRACING_V2')}\")\n",
        "print(f\"LANGCHAIN_API_KEY is set: {os.environ.get('LANGCHAIN_API_KEY') is not None}\")\n",
        "print(f\"LANGCHAIN_PROJECT: {os.environ.get('LANGCHAIN_PROJECT')}\")\n",
        "print(f\"LANGCHAIN_ENDPOINT: {os.environ.get('LANGCHAIN_ENDPOINT')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UAISXGH8oD7",
        "outputId": "a7058d38-95eb-49bd-962a-43e885d9ed0d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LANGCHAIN_TRACING_V2: true\n",
            "LANGCHAIN_API_KEY is set: True\n",
            "LANGCHAIN_PROJECT: Agentic AI exp\n",
            "LANGCHAIN_ENDPOINT: https://api.smith.langchain.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "868d24e5"
      },
      "source": [
        "### Creating Inbuild tools in Langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMXvs6LCj6Pe",
        "outputId": "37dc9eb5-92fc-4fb6-a626-0e24a0b13a4e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/usr/local/lib/python3.11/dist-packages/wikipedia/__init__.py'>, top_k_results=3, lang='en', load_all_available_meta=False, doc_content_chars_max=4000)),\n",
              " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=3, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=4000))]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "from langchain_community.tools import ArxivQueryRun, WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper, ArxivAPIWrapper\n",
        "\n",
        "api_wrapper_wiki = WikipediaAPIWrapper()\n",
        "api_wrapper_arxiv = ArxivAPIWrapper()\n",
        "\n",
        "wiki_tool = WikipediaQueryRun(api_wrapper=api_wrapper_wiki)\n",
        "arxiv_tool = ArxivQueryRun(api_wrapper=api_wrapper_arxiv)\n",
        "\n",
        "tools = [wiki_tool, arxiv_tool]\n",
        "tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "920332da"
      },
      "source": [
        "### Custom Tools - RAG Tool"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "loader = WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
        "data = loader.load()\n",
        "documents = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(data)\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "db = Chroma.from_documents(documents, embeddings)\n",
        "retriever = db.as_retriever()\n",
        "retriever\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsKqUYe90zCa",
        "outputId": "85fb3661-6295-4c8a-faa2-03dea729155f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7c2c3096ead0>, search_kwargs={})"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools.retriever import create_retriever_tool\n",
        "\n",
        "retriever_tool = create_retriever_tool(retriever, \"langchain-docs\", \"Searches the langchain docs for answers.\")\n",
        "retriever_tool"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJIrvF6C3QMD",
        "outputId": "e14c9864-eff2-4409-aaa3-70f07e4158d6"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tool(name='langchain-docs', description='Searches the langchain docs for answers.', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x7c2aa3e66ac0>, retriever=VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7c2c3096ead0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x7c2aa3e9a340>, retriever=VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7c2c3096ead0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools=[wiki_tool, arxiv_tool, retriever_tool]\n",
        "print(len(tools))\n",
        "tools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwZA29Ou3pJP",
        "outputId": "611a4d3a-14bd-4cc6-ea74-71d50e30bc16"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/usr/local/lib/python3.11/dist-packages/wikipedia/__init__.py'>, top_k_results=3, lang='en', load_all_available_meta=False, doc_content_chars_max=4000)),\n",
              " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=3, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=4000)),\n",
              " Tool(name='langchain-docs', description='Searches the langchain docs for answers.', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x7c2aa3e66ac0>, retriever=VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7c2c3096ead0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x7c2aa3e9a340>, retriever=VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7c2c3096ead0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the tools with Agents"
      ],
      "metadata": {
        "id": "YyLii8n04OKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from google.colab import userdata\n",
        "\n",
        "GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
        "llm = ChatGroq(groq_api_key=GROQ_API_KEY, model=\"llama-3.1-8b-instant\")\n",
        "llm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAuk-vqz3_00",
        "outputId": "215a7d8a-0649-4e4c-9480-cab5ab9d4761"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7c2ac1e4d510>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7c2ac1e4cd50>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "prompt=hub.pull(\"hwchase17/openai-functions-agent\")\n",
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwaer5Fm6vTB",
        "outputId": "27f714a7-d85a-4881-c691-206ce3d3e3e1"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x7c2c1a20ec00>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x7c2c1a20ec00>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import create_openai_tools_agent\n",
        "\n",
        "agent = create_openai_tools_agent(\n",
        "    llm=llm,\n",
        "    tools=tools,\n",
        "    prompt=prompt\n",
        ")\n"
      ],
      "metadata": {
        "id": "2nxRGkBT8r8o"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentExecutor\n",
        "\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "agent_executor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFAOP-uI8_EK",
        "outputId": "4d293a95-c591-465a-fbfc-e1752a1a1247"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
              "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
              "})\n",
              "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x7c2c1a20ec00>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x7c2c1a20ec00>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
              "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7c2ac1e4d510>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7c2ac1e4cd50>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'langchain-docs', 'description': 'Searches the langchain docs for answers.', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
              "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/usr/local/lib/python3.11/dist-packages/wikipedia/__init__.py'>, top_k_results=3, lang='en', load_all_available_meta=False, doc_content_chars_max=4000)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=3, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=4000)), Tool(name='langchain-docs', description='Searches the langchain docs for answers.', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x7c2aa3e66ac0>, retriever=VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7c2c3096ead0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x7c2aa3e9a340>, retriever=VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7c2c3096ead0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke({\"input\":\"Tell me about Langsmith\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtJI4VWs9I11",
        "outputId": "025bd9ec-070f-47bb-d99e-1db657ff9a75"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `langchain-docs` with `{'query': 'Langsmith'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[38;5;200m\u001b[1;3mGet started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith\n",
            "\n",
            "Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith\n",
            "\n",
            "LangSmith + LangChain OSSLangSmith is framework-agnostic ‚Äî¬†it can be used with or without LangChain's open source frameworks langchain and langgraph.If you are using either of these, you can enable LangSmith tracing with a single environment variable.\n",
            "For more see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\n",
            "Observability‚Äã\n",
            "Observability is important for any software application, but especially so for LLM applications. LLMs are non-deterministic by nature, meaning they can produce unexpected results. This makes them trickier than normal to debug.\n",
            "This is where LangSmith can help! LangSmith has LLM-native observability, allowing you to get meaningful insights from your application. LangSmith‚Äôs observability features have you covered throughout all stages of application development - from prototyping, to beta testing, to production.\n",
            "\n",
            "LangSmith + LangChain OSSLangSmith is framework-agnostic ‚Äî¬†it can be used with or without LangChain's open source frameworks langchain and langgraph.If you are using either of these, you can enable LangSmith tracing with a single environment variable.\n",
            "For more see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\n",
            "Observability‚Äã\n",
            "Observability is important for any software application, but especially so for LLM applications. LLMs are non-deterministic by nature, meaning they can produce unexpected results. This makes them trickier than normal to debug.\n",
            "This is where LangSmith can help! LangSmith has LLM-native observability, allowing you to get meaningful insights from your application. LangSmith‚Äôs observability features have you covered throughout all stages of application development - from prototyping, to beta testing, to production.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `wikipedia` with `{'query': 'Langsmith'}`\n",
            "\n",
            "\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=d394cc2c-1c09-48c8-918d-b661713c7d96; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=c7282c44-0e83-4337-bce5-5d0716464fee; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=7721ab25-eede-4447-8027-2c1b2e298c78; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=940f899d-9b35-43cf-8fc9-d635eedf8f31; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=8da8c32a-9277-498d-9d05-488c8bf015ee; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=8da8c32a-9277-498d-9d05-488c8bf015ee; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=940f899d-9b35-43cf-8fc9-d635eedf8f31; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=7721ab25-eede-4447-8027-2c1b2e298c78; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=6538ca08-018d-485f-92e9-7143543d31f2; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=6538ca08-018d-485f-92e9-7143543d31f2; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=4f6d6881-b8a2-471a-a195-8885a8d127a2; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=4f6d6881-b8a2-471a-a195-8885a8d127a2; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=096038ec-5a2f-438e-8af1-5f650a614086; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=096038ec-5a2f-438e-8af1-5f650a614086; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=c7282c44-0e83-4337-bce5-5d0716464fee; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=73494531-6150-43f2-9cda-c6f0222d96de; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=81cb4984-9a5a-4721-8b32-7f074480ed81; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=81cb4984-9a5a-4721-8b32-7f074480ed81; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=73494531-6150-43f2-9cda-c6f0222d96de; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=70637d26-ed1e-4b4a-a1e2-0a0559b3df88; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=1c18268d-ffe9-4065-82cf-5c758c354c9f; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=67310ebe-ac2d-4347-8e71-636729230cc8; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=1950e921-602d-4905-93c9-f5bba1721361; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=1950e921-602d-4905-93c9-f5bba1721361; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=67310ebe-ac2d-4347-8e71-636729230cc8; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=1c18268d-ffe9-4065-82cf-5c758c354c9f; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=7801a3ce-41c1-4a02-897e-d5615041a5cb; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=7801a3ce-41c1-4a02-897e-d5615041a5cb; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=4c08ebc1-85c0-4124-9670-766fc3089d44; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=4c08ebc1-85c0-4124-9670-766fc3089d44; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=329b2b0d-86a1-4414-b4f7-e38bb2caddb2; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=329b2b0d-86a1-4414-b4f7-e38bb2caddb2; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=70637d26-ed1e-4b4a-a1e2-0a0559b3df88; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=c9ce00ef-3aa1-4845-90a6-4cc1f9d77607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36;1m\u001b[1;3mPage: LangChain\n",
            "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
            "\n",
            "\u001b[0m\u001b[32;1m\u001b[1;3mIt appears that there is not enough information available about Langsmith in Wikipedia and Langchain-docs.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Tell me about Langsmith',\n",
              " 'output': 'It appears that there is not enough information available about Langsmith in Wikipedia and Langchain-docs.'}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke({\"input\":\"what is artificial intelligence?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhC3JJHg_qbh",
        "outputId": "624d6c9c-e436-406b-ae5b-c5e6db4f2059"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `wikipedia` with `{'query': 'Artificial intelligence'}`\n",
            "\n",
            "\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=c9ce00ef-3aa1-4845-90a6-4cc1f9d77607; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=be75cba8-712c-448e-a37e-3be6976de531; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=e0b22c39-db71-413c-8090-fbebee0aeff1; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=c7d17db5-63b9-418b-b3a6-fae2020501bc; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=61a0415a-d6c8-4c21-aad6-cf4da10b3789; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=61a0415a-d6c8-4c21-aad6-cf4da10b3789; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=c7d17db5-63b9-418b-b3a6-fae2020501bc; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=e0b22c39-db71-413c-8090-fbebee0aeff1; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=f772ac0b-8db0-4090-8bb0-ed59893b7774; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=f772ac0b-8db0-4090-8bb0-ed59893b7774; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=458c1308-f15d-4747-b12d-933aaa8c8f68; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=458c1308-f15d-4747-b12d-933aaa8c8f68; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=74f40ba9-9c54-4011-b3af-3bbd4e89f7b0; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=74f40ba9-9c54-4011-b3af-3bbd4e89f7b0; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=be75cba8-712c-448e-a37e-3be6976de531; trace=d394cc2c-1c09-48c8-918d-b661713c7d96,id=d394cc2c-1c09-48c8-918d-b661713c7d96; trace=d809634c-521f-450b-9c2d-88822f562c13,id=d809634c-521f-450b-9c2d-88822f562c13; trace=d809634c-521f-450b-9c2d-88822f562c13,id=e80c89ba-5ee1-4de9-b8e2-ac3b8d037390; trace=d809634c-521f-450b-9c2d-88822f562c13,id=e4a2faa3-5db1-4158-bae7-d4894e13e385; trace=d809634c-521f-450b-9c2d-88822f562c13,id=32e15678-030c-4f5a-a268-68f49d19b805; trace=d809634c-521f-450b-9c2d-88822f562c13,id=c0a688f0-34c9-4ed6-abe9-b7f69b96c1e2; trace=d809634c-521f-450b-9c2d-88822f562c13,id=c0a688f0-34c9-4ed6-abe9-b7f69b96c1e2; trace=d809634c-521f-450b-9c2d-88822f562c13,id=32e15678-030c-4f5a-a268-68f49d19b805; trace=d809634c-521f-450b-9c2d-88822f562c13,id=e4a2faa3-5db1-4158-bae7-d4894e13e385; trace=d809634c-521f-450b-9c2d-88822f562c13,id=9f71c9fc-69c1-48ea-b2bb-d99f26bd29e6; trace=d809634c-521f-450b-9c2d-88822f562c13,id=9f71c9fc-69c1-48ea-b2bb-d99f26bd29e6; trace=d809634c-521f-450b-9c2d-88822f562c13,id=63c6fe8e-2835-4144-b3c2-773bcfba21be; trace=d809634c-521f-450b-9c2d-88822f562c13,id=63c6fe8e-2835-4144-b3c2-773bcfba21be; trace=d809634c-521f-450b-9c2d-88822f562c13,id=534efbdd-d419-4e5b-92de-11eb2853cfb7; trace=d809634c-521f-450b-9c2d-88822f562c13,id=534efbdd-d419-4e5b-92de-11eb2853cfb7; trace=d809634c-521f-450b-9c2d-88822f562c13,id=e80c89ba-5ee1-4de9-b8e2-ac3b8d037390; trace=d809634c-521f-450b-9c2d-88822f562c13,id=fcb61553-22f7-4e55-bf68-c103a407625a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36;1m\u001b[1;3mPage: Artificial intelligence\n",
            "Summary: Artificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals.\n",
            "High-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., language models and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\"\n",
            "Various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields. Some companies, such as OpenAI, Google DeepMind and Meta, aim to create artificial general intelligence (AGI)—AI that can complete virtually any cognitive task at least as well as a human.\n",
            "Artificial intelligence was founded as an academic discipline in 1956, and the field went through multiple cycles of optimism throughout its history, followed by periods of disappointment and loss of funding, known as AI winters. Funding and interest vastly increased after 2012 when graphics processing units started being used to accelerate neural networks and deep learning outperformed previous AI techniques. This growth accelerated further after 2017 with the transformer architecture. In the 2020s, an ongoing period of rapid progress in advanced generative AI became known as the AI boom. Generative AI's ability to create and modify content has led to several unintended consequences and harms, which has raised ethical concerns about AI's long-term effects and potential existential risks, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.\n",
            "\n",
            "Page: Artificial general intelligence\n",
            "Summary: Artificial general intelligence (AGI)—sometimes called human‑level intelligence AI—is a type of artificial intelligence that would match or surpass human capabilities across virtually all cognitive tasks.\n",
            "Some researchers argue that state‑of‑the‑art large language models (LLMs) already exhibit signs of AGI‑level capability, while others maintain that genuine AGI has not yet been achieved. Beyond AGI, artificial superintelligence (ASI) would outperform the best human abilities across every domain by a wide margin.\n",
            "Unlike artificial narrow intelligence (ANI), whose competence is confined to well‑defined tasks, an AGI system can generalise knowledge, transfer skills between domains, and solve novel problems without task‑specific reprogramming. The concept does not, in principle, require the system to be an autonomous agent; a static model—such as a highly capable large language model—or an embodied robot could both satisfy the definition so long as human‑level breadth and proficiency are achieved.\n",
            "Creating AGI is a primary goal of AI research and of companies such as OpenAI, Google, and Meta. A 2020\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=d809634c-521f-450b-9c2d-88822f562c13,id=fcb61553-22f7-4e55-bf68-c103a407625a; trace=d809634c-521f-450b-9c2d-88822f562c13,id=a17aa9be-e206-41ab-9350-99f94886966e; trace=d809634c-521f-450b-9c2d-88822f562c13,id=c0f3af53-2660-4f4c-82bf-76a4913dd36d; trace=d809634c-521f-450b-9c2d-88822f562c13,id=f6325664-68cc-41eb-bba5-bdd66f78dbdb; trace=d809634c-521f-450b-9c2d-88822f562c13,id=2ac184f4-1de9-4296-bb46-f11978dd3346; trace=d809634c-521f-450b-9c2d-88822f562c13,id=2ac184f4-1de9-4296-bb46-f11978dd3346; trace=d809634c-521f-450b-9c2d-88822f562c13,id=f6325664-68cc-41eb-bba5-bdd66f78dbdb; trace=d809634c-521f-450b-9c2d-88822f562c13,id=c0f3af53-2660-4f4c-82bf-76a4913dd36d; trace=d809634c-521f-450b-9c2d-88822f562c13,id=bc7607fd-6eee-42cb-a0d1-a4c7f778a375; trace=d809634c-521f-450b-9c2d-88822f562c13,id=bc7607fd-6eee-42cb-a0d1-a4c7f778a375; trace=d809634c-521f-450b-9c2d-88822f562c13,id=0df038d4-6e4e-4e94-878a-862318b96f72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mIt seems like the text got cut off. I'll provide the full response.\n",
            "\n",
            "Since the provided information does not fully answer your question, I'll provide more information on the topic.\n",
            "\n",
            "Artificial general intelligence (AGI) is a type of artificial intelligence that aims to match or surpass human capabilities across virtually all cognitive tasks. This includes reasoning, problem-solving, learning, and decision-making, among others.\n",
            "\n",
            "AGI is considered a more advanced form of artificial intelligence, as it is designed to be more versatile and able to perform a wide range of tasks, rather than being limited to a specific task or set of tasks.\n",
            "\n",
            "There are different types of AGI, including:\n",
            "\n",
            "1. Narrow or weak AGI: This type of AGI is designed to perform a specific task or set of tasks, but is not capable of general reasoning or problem-solving.\n",
            "2. General or strong AGI: This type of AGI is designed to be capable of general reasoning and problem-solving, and is able to learn and adapt to new situations.\n",
            "3. Superintelligence: This type of AGI is significantly more intelligent than the best human minds, and is able to perform tasks that are beyond human capabilities.\n",
            "\n",
            "The development of AGI is an active area of research, and there are many different approaches being explored, including the use of machine learning, neural networks, and cognitive architectures.\n",
            "\n",
            "Some of the potential benefits of AGI include:\n",
            "\n",
            "1. Improved decision-making: AGI could be used to make decisions that are more informed and accurate than those made by humans.\n",
            "2. Increased productivity: AGI could be used to automate many routine tasks, freeing up humans to focus on more complex and creative tasks.\n",
            "3. Enhanced learning: AGI could be used to develop personalized learning plans for individuals, and to provide real-time feedback and assessment.\n",
            "\n",
            "However, there are also potential risks and challenges associated with the development of AGI, including:\n",
            "\n",
            "1. Job displacement: AGI could potentially displace human workers in many industries, leading to unemployment and social unrest.\n",
            "2. Bias and discrimination: AGI systems may perpetuate existing biases and discrimination if they are trained on biased data.\n",
            "3. Safety and security: AGI systems may be vulnerable to cyber attacks and other security threats, and may pose a risk to human safety if they are not designed with safety and security in mind.\n",
            "\n",
            "Overall, the development of AGI is a complex and multifaceted issue, and there are many different perspectives and opinions on the potential benefits and risks.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'what is artificial intelligence?',\n",
              " 'output': \"It seems like the text got cut off. I'll provide the full response.\\n\\nSince the provided information does not fully answer your question, I'll provide more information on the topic.\\n\\nArtificial general intelligence (AGI) is a type of artificial intelligence that aims to match or surpass human capabilities across virtually all cognitive tasks. This includes reasoning, problem-solving, learning, and decision-making, among others.\\n\\nAGI is considered a more advanced form of artificial intelligence, as it is designed to be more versatile and able to perform a wide range of tasks, rather than being limited to a specific task or set of tasks.\\n\\nThere are different types of AGI, including:\\n\\n1. Narrow or weak AGI: This type of AGI is designed to perform a specific task or set of tasks, but is not capable of general reasoning or problem-solving.\\n2. General or strong AGI: This type of AGI is designed to be capable of general reasoning and problem-solving, and is able to learn and adapt to new situations.\\n3. Superintelligence: This type of AGI is significantly more intelligent than the best human minds, and is able to perform tasks that are beyond human capabilities.\\n\\nThe development of AGI is an active area of research, and there are many different approaches being explored, including the use of machine learning, neural networks, and cognitive architectures.\\n\\nSome of the potential benefits of AGI include:\\n\\n1. Improved decision-making: AGI could be used to make decisions that are more informed and accurate than those made by humans.\\n2. Increased productivity: AGI could be used to automate many routine tasks, freeing up humans to focus on more complex and creative tasks.\\n3. Enhanced learning: AGI could be used to develop personalized learning plans for individuals, and to provide real-time feedback and assessment.\\n\\nHowever, there are also potential risks and challenges associated with the development of AGI, including:\\n\\n1. Job displacement: AGI could potentially displace human workers in many industries, leading to unemployment and social unrest.\\n2. Bias and discrimination: AGI systems may perpetuate existing biases and discrimination if they are trained on biased data.\\n3. Safety and security: AGI systems may be vulnerable to cyber attacks and other security threats, and may pose a risk to human safety if they are not designed with safety and security in mind.\\n\\nOverall, the development of AGI is a complex and multifaceted issue, and there are many different perspectives and opinions on the potential benefits and risks.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    }
  ]
}